{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afaf8039",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: Qwen\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f1e0d",
   "metadata": {},
   "source": [
    "# ChatQwen\n",
    "\n",
    "This will help you get started with Qwen [chat models](../../concepts/chat_models.mdx). For detailed documentation of all ChatQwen features and configurations head to the [API reference](https://pypi.org/project/langchain-qwq/).\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "\n",
    "| Class | Package | Local | Serializable | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: |  :---: | :---: | :---: |\n",
    "| [ChatQwen](https://pypi.org/project/langchain-qwq/) | [langchain-qwq](https://pypi.org/project/langchain-qwq/) | ‚ùå | beta | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-qwq?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-qwq?style=flat-square&label=%20) |\n",
    "\n",
    "### Model features\n",
    "| [Tool calling](../../how_to/tool_calling.ipynb) | [Structured output](../../how_to/structured_output.ipynb) | JSON mode | [Image input](../../how_to/multimodal_inputs.ipynb) | Audio input | Video input | [Token-level streaming](../../how_to/chat_streaming.ipynb) | Native async | [Token usage](../../how_to/chat_token_usage_tracking.ipynb) | [Logprobs](../../how_to/logprobs.ipynb) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| ‚úÖ | ‚úÖ | ‚úÖ |‚úÖ  | ‚ùå | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | \n",
    "\n",
    "## Setup\n",
    "\n",
    "To access Qwen models you'll need to create an Alibaba Cloud account, get an API key, and install the `langchain-qwq` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to [Alibaba's API Key page](https://account.alibabacloud.com/login/login.htm?oauth_callback=https%3A%2F%2Fbailian.console.alibabacloud.com%2F%3FapiKey%3D1&lang=en#/api-key) to sign up to Alibaba Cloud and generate an API key. Once you've done this set the `DASHSCOPE_API_KEY` environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433e8d2b-9519-4b49-b2c4-7ab65b046c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"DASHSCOPE_API_KEY\"):\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass(\"Enter your Dashscope API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730d6a1-c893-4840-9817-5e5251676d5d",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain Qwen integration lives in the `langchain-qwq` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d6238-1f87-422a-b135-f5abbb8652fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-qwq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cde65-254d-4219-a441-068766c0d4b5",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today? üòä', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-flash'}, id='run--f68b2865-b969-47a0-ad1f-b88bb3b5906b-0', usage_metadata={'input_tokens': 9, 'output_tokens': 11, 'total_tokens': 20, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_qwq import ChatQwen\n",
    "\n",
    "\n",
    "llm = ChatQwen(model=\"qwen-flash\")\n",
    "response = llm.invoke(\"Hello\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e0dbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-flash'}, id='run--40f2e75b-7d28-4a71-8f5f-561509ac2010-0', usage_metadata={'input_tokens': 32, 'output_tokens': 8, 'total_tokens': 40, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French.\"\n",
    "        \"Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](../../how_to/sequence.ipynb) our model with a prompt template like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ich liebe Programmierung.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-flash'}, id='run--ed052510-82f4-4dc5-a7f1-761a792c0dd4-0', usage_metadata={'input_tokens': 28, 'output_tokens': 5, 'total_tokens': 33, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates\"\n",
    "            \"{input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b3ef3",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "ChatQwen supports tool calling API that lets you describe tools and their arguments, and have the model return a JSON object with a tool to invoke and the inputs to that tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1a355",
   "metadata": {},
   "source": [
    "### Use with `bind_tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15fb6a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_f0c2cc49307f480db78a45', 'function': {'arguments': '{\"first_int\": 5, \"second_int\": 42}', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={'finish_reason': 'tool_calls', 'model_name': 'qwen-flash'} id='run--27c5aafb-9710-42f5-ab78-5a2ad1d9050e-0' tool_calls=[{'name': 'multiply', 'args': {'first_int': 5, 'second_int': 42}, 'id': 'call_f0c2cc49307f480db78a45', 'type': 'tool_call'}] usage_metadata={'input_tokens': 166, 'output_tokens': 27, 'total_tokens': 193, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_qwq import ChatQwen\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int\n",
    "\n",
    "\n",
    "llm = ChatQwen(model=\"qwen-flash\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "msg = llm_with_tools.invoke(\"What's 5 times forty two\")\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ffd89-c474-45a7-a123-e0b1d362f54f",
   "metadata": {},
   "source": [
    "### vision Support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a7d46-d1f6-4ae8-835a-266ca47e4daf",
   "metadata": {},
   "source": [
    "#### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f69db3-fa51-4b9a-885c-1353968066e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='In this image, I see a heartwarming scene on a sandy beach during what appears to be either sunrise or sunset, given the warm, soft golden light. A woman is sitting on the sand, smiling warmly as she gently holds the paw of a large, light-colored dog‚Äîlikely a Labrador Retriever. The dog is sitting upright, facing her, and seems to be engaging in a friendly handshake or high-five gesture with her. \\n\\nThe woman is wearing a plaid shirt and dark pants, and her long hair flows loosely. She looks happy and relaxed, enjoying the moment with her pet. The dog is wearing a colorful harness with patterns, and a leash lies loosely on the sand nearby. \\n\\nIn the background, gentle waves roll onto the shore, and the horizon blends softly into the sky, creating a serene and peaceful atmosphere. The overall mood of the image is joyful, affectionate, and tranquil, capturing a special bond between the woman and her dog in a beautiful natural setting.' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-vl-max-latest'} id='run--22fecc27-9455-4426-bbd4-aa5a5bde400c-0' usage_metadata={'input_tokens': 1265, 'output_tokens': 202, 'total_tokens': 1467, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatQwen(model=\"qwen-vl-max-latest\")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=[\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": \"https://example.com/image.jpg\"\n",
    "            },\n",
    "        },\n",
    "        {\"type\": \"text\", \"text\": \"What do you see in this image?\"},\n",
    "    ])\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1faea19-932f-4dc8-b0af-60e3507eee08",
   "metadata": {},
   "source": [
    "#### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59355c38-d3e2-4051-811a-2b99286ea01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='This video features a young woman with short, neatly styled brown hair and bangs. She is wearing a soft pink knitted cardigan over a white top, accessorized with a delicate necklace. The background is softly blurred, suggesting an outdoor urban setting with modern buildings, possibly during daytime with natural lighting.\\n\\nThroughout the video, the woman maintains a warm and friendly demeanor, smiling gently and occasionally laughing. Her expressions are animated and cheerful, conveying a sense of happiness and approachability. The lighting highlights her features beautifully, giving the scene a pleasant and inviting atmosphere.\\n\\nThe watermark in the top-right corner indicates that this video was created using AI synthesis technology (\"ÈÄö‰πâ¬∑AIÂêàÊàê\"), suggesting that the content may be generated or enhanced by artificial intelligence. This could mean the visuals are highly polished and stylized, typical of AI-generated media.\\n\\nOverall, the video appears to be a short, positive, and uplifting clip, possibly intended for use in promotional content, social media, or as part of a digital character presentation.' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-vl-max-latest'} id='run--c567a6e2-14e0-47e1-acb6-cfe2953fb1ad-0' usage_metadata={'input_tokens': 3607, 'output_tokens': 204, 'total_tokens': 3811, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatQwen(model=\"qwen-vl-max-latest\")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=[\n",
    "        {\n",
    "            \"type\": \"video_url\",\n",
    "            \"video_url\": {\n",
    "                \"url\": \"https://example.com/video.mp4\"\n",
    "            },\n",
    "        },\n",
    "        {\"type\": \"text\", \"text\": \"Can you tell me about this video?\"},\n",
    "    ])\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatQwen features and configurations head to the [API reference](https://pypi.org/project/langchain-qwq/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1026e3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
